{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP ML Engineer Code Challenge Writeup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document contains:<br>\n",
    "I. challenge prompt answers <br>\n",
    "II. an additional section where I explored data, techniques, results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Prompt answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. How would you evaluate your autocomplete server? b. If you made another version, how would you compare the two to decide which is better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. If the software was designed with more general corpus-intake functionality, performance of ranking, completion return, and run time could be evaluated by comparison against published results on known datasets. \n",
    "\n",
    "An A/B test in which human interaction with the software was recorded could provide another means of evaluation. The control would be conversations without autocompletions. Generally, metrics would fall along these lines, and be implemented statistically: Prefixes with ~3-12 characters should have completion sets. Selection time should be limited. Selections should occur for completion sets. Completions that are never or seldom selected should be marked for re-evaluation in text manifestation and rank in completion lists. Completions in top positions of selection lists offered should be selected more than those at the end. With autocompletions, conversation time should be decreased, and customer-reported satisfaction higher. \n",
    "\n",
    "Run time should be evaluated, the presence of bottlenecks discerned. A test suite of customer service representative-generated prefixes, as well as non-sensical prefixes, could be run and average length of completion lists for both sets evaluated. Grammar, spelling, capitalization, and punctuation correction still need to be implemented on completions in the current library—it'd be good to run tests on those attributes of the text provided for the autocompletions. <br>\n",
    "\n",
    "b. I would compare performance times, test suite results, and A/B test results between the versions. The next version would include sentence detection and separate sentences prior to matching and ranking, as well as correct grammar and spelling on completions, provide ranking on more than corpus frequency (perhaps incorporating conversation topic, company information, customer information and information on the representative)—so, tests could be designed to determine the comparative efficacy of the implementation of those features. Also, from a development perspective, the logging system should be evaluated for usefulness—the current logging system is catching exceptions that are too general, and logs verbosely—this should be improved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One way to improve the autocomplete server is to give topic-specific suggestions. How would you design an auto-categorization server? It should take a list of messages and return a TopicId. (Assume that every conversation in the training set has a TopicId)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each possible completion could have a stored list of topic IDs ranked according to the frequency of the completion naturally occurring, and selected from options, in conversations with each topic. Completions matching prefixes with high ranking matching topic IDs could be more weighted more heavily in the overall match ranking system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How would you evaluate if your auto-categorization server is good?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate topic extraction performance with respect to AUC, precision, recall and F1 against results published on known datasets. Run A/B test to determine if the completions offered at runtime are selected more quickly, and more often, than non-topic weighted completions; if conversations with topic-weighted autocompletions rated more highly by customers and take less time on average. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The autocomplete server data set we gave you is pretty small, so it doesn't take very long to load and it's fine to process on server startup.  How would you change your design if the dataset was several gigabytes?  What if it was 100 terabytes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would not process the data set on server startup, but store a precomputed autocompletion system that allows for efficient lookups. For data storage, I would evaluate the cost and efficacy of multiple operational datastores at different scales, and more archival datastores for redundancy. This is subject I would need to learn more about to do well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What would we need to do if we had millions of agents using the Autocomplete service at the same time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the service with a framework like [Dask](https://dask.org/) on something like a cluster of AWS EC2 nodes. Serverless computing would help facilitate scalability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Code, data, and results exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.io.json import json_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOC = os.path.abspath(\"{}/../../\".format(\"challenge_writeup.ipynb\"))\n",
    "sys.path.insert(0, \"{}/library\".format(AUTOC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_load import data_load as dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dl.DataLoad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect time for json_normalize; shape, information on json_normalized data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "convos = [convo for convo in data.json['Issues']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.6 ms, sys: 1.96 ms, total: 25.6 ms\n",
      "Wall time: 24.3 ms\n"
     ]
    }
   ],
   "source": [
    "%time convos_normalized = json_normalize(convos, 'Messages', ['CompanyGroupId', 'IssueId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IsFromCustomer</th>\n",
       "      <th>Text</th>\n",
       "      <th>CompanyGroupId</th>\n",
       "      <th>IssueId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>Hi! I placed an order on your website and I ca...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>I think I used my email address to log in.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>My battery exploded!</td>\n",
       "      <td>1</td>\n",
       "      <td>10001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>It's on fire, it's melting the carpet!</td>\n",
       "      <td>1</td>\n",
       "      <td>10001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>What should I do!</td>\n",
       "      <td>1</td>\n",
       "      <td>10001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IsFromCustomer                                               Text  \\\n",
       "0            True  Hi! I placed an order on your website and I ca...   \n",
       "1            True         I think I used my email address to log in.   \n",
       "2            True                               My battery exploded!   \n",
       "3            True             It's on fire, it's melting the carpet!   \n",
       "4            True                                  What should I do!   \n",
       "\n",
       "   CompanyGroupId  IssueId  \n",
       "0               1        1  \n",
       "1               1        1  \n",
       "2               1    10001  \n",
       "3               1    10001  \n",
       "4               1    10001  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convos_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: We now have 1 row per text message. Number of messages ('NumTextMessages': 22264) matches number of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22264 entries, 0 to 22263\n",
      "Data columns (total 4 columns):\n",
      "IsFromCustomer    22264 non-null bool\n",
      "Text              22264 non-null object\n",
      "CompanyGroupId    22264 non-null int64\n",
      "IssueId           22264 non-null int64\n",
      "dtypes: bool(1), int64(2), object(1)\n",
      "memory usage: 543.6+ KB\n"
     ]
    }
   ],
   "source": [
    "convos_normalized.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out time to return customer service reps' messages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.61 ms, sys: 2.05 ms, total: 6.66 ms\n",
      "Wall time: 5.16 ms\n"
     ]
    }
   ],
   "source": [
    "%time outbound = convos_normalized.loc[np.where(np.equal(convos_normalized[\"IsFromCustomer\"], False))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at outbound messages prepped for use in autocompletions in library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_prep import data_prep as dp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prepped = dp.DataPrep(data.json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9             b'Hello Werner how may I help you today?'\n",
       "11    b'Sure I can help you with that? Could you ple...\n",
       "13      b'Let me update that information on our system'\n",
       "14    b'OK Wernzio, I have updated your address to t...\n",
       "16    b'Ok let me go ahead and request a work order ...\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_prepped.outbound_messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                                                 11060\n",
       "unique                                                 8452\n",
       "top       b'Is there anything else I can help you with t...\n",
       "freq                                                    191\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_prepped.outbound_messages.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autocompletion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autocomplete import autocompleter as a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoc = a.Autocompleter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at docstrings, code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "??autoc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out prefix: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = a.Prefix(\"How can\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "re.compile(rb'How can', re.IGNORECASE)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix.compiled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out time and returns of autocomplete suggestions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.4 ms, sys: 1.38 ms, total: 11.8 ms\n",
      "Wall time: 10.7 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[b'Is there anything else I can help you with today?',\n",
       " b'Is there anything else I can assist you with?',\n",
       " b'Is there anything else I can help you with?',\n",
       " b'Is there anything else I can assist you with today?',\n",
       " b'is there anything else i can help you with today']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time autoc.generate_completions(\"is th\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autocomplete",
   "language": "python",
   "name": "autocomplete"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
